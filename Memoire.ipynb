{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Memoire.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8INfzdZ32q6"
      },
      "outputs": [],
      "source": [
        "#Import Essential Libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import io \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wge41njBAm-m",
        "outputId": "ff6966e1-5dc7-4cf6-84f1-8dba21f3ab4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "  \n",
        "  \n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "6JT-BjtK4AsN",
        "outputId": "aecc004a-33f2-4a4a-c696-485ca1543081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-473d95fc-6ab5-452c-a319-920c78440fa6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-473d95fc-6ab5-452c-a319-920c78440fa6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_memoire.xlsx to data_memoire.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel(io.BytesIO(uploaded['data_memoire.xlsx'])) \n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ndk3oAC7ykn",
        "outputId": "d3d9fb3d-f19a-4973-ca5d-f6339ecbf2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Derivation cohort  LOS_Y  LOS  Death   Age  Severity  MI  PVD  CHF  CVD  \\\n",
            "0                     1      1    1      0   >80         3   0    0    0    0   \n",
            "1                     1      1    2      1   >60         7   0    1    0    0   \n",
            "2                     1      1    2      1   >80         7   0    1    1    1   \n",
            "3                     1      1   15      0   >70         9   1    0    0    0   \n",
            "4                     1      1    9      0   >70         7   0    0    0    0   \n",
            "...                 ...    ...  ...    ...   ...       ...  ..  ...  ...  ...   \n",
            "4706                  0      1    4      0   >70         4   0    0    0    0   \n",
            "4707                  0      1    2      0   >60         2   0    1    0    0   \n",
            "4708                  0      0    0      0   >60         1   0    1    0    0   \n",
            "4709                  0      0    0      0   >80         3   0    1    0    0   \n",
            "4710                  0      0    0      0  0-60         2   0    1    0    0   \n",
            "\n",
            "      ...  Ferritin > 300  CrctProtYes  CrctProtein  C-Reactive Prot > 10  \\\n",
            "0     ...               0            1       0.4999                     0   \n",
            "1     ...               1            1      14.9000                     1   \n",
            "2     ...               1            1      33.9000                     1   \n",
            "3     ...               1            1      18.4000                     1   \n",
            "4     ...               1            1      11.6000                     1   \n",
            "...   ...             ...          ...          ...                   ...   \n",
            "4706  ...               0            1       1.8000                     0   \n",
            "4707  ...               1            1       3.1000                     0   \n",
            "4708  ...               0            1       0.4999                     0   \n",
            "4709  ...               1            1       8.6000                     0   \n",
            "4710  ...               0            1       0.0000                     0   \n",
            "\n",
            "      ProCalCYes  Procalcitonin  Procalciton > 0.1  TropYes  Troponin  \\\n",
            "0              0         0.0000                  0        1      0.01   \n",
            "1              1         0.6000                  1        1      1.20   \n",
            "2              1         1.2000                  1        0      0.00   \n",
            "3              1         7.3000                  1        1      0.05   \n",
            "4              0         0.0000                  0        1      0.01   \n",
            "...          ...            ...                ...      ...       ...   \n",
            "4706           1         0.0999                  0        1      0.01   \n",
            "4707           1         0.0999                  0        1      0.01   \n",
            "4708           1         0.0000                  0        0      0.00   \n",
            "4709           1         0.1000                  0        1      0.01   \n",
            "4710           1         0.0000                  0        0      0.00   \n",
            "\n",
            "      Troponin > 0.1  \n",
            "0                  0  \n",
            "1                  1  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "...              ...  \n",
            "4706               0  \n",
            "4707               0  \n",
            "4708               0  \n",
            "4709               0  \n",
            "4710               0  \n",
            "\n",
            "[4711 rows x 81 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
            "  warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.groupby(['Death'],).size()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CThI_dSsPTe9",
        "outputId": "91501f43-f7b3-4c86-c989-35c2928754ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Death\n",
              "0    3563\n",
              "1    1148\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visulalisation et analyse \n",
        "  #Afficher le nom de chaque colonne\n",
        "data.columns.sort_values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_v4je8X8plA",
        "outputId": "69ba543d-8a6b-487c-df95-b8a9d6377977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ALT', 'ALT > 40', 'ALTYes', 'AST', 'AST > 40', 'ASTYes', 'Age',\n",
              "       'Age.1', 'AgeScore', 'All CNS', 'BUN', 'BUN > 30', 'BUNYes',\n",
              "       'C-Reactive Prot > 10', 'CHF', 'COPD', 'CVD', 'CrctProtYes',\n",
              "       'CrctProtein', 'Creatinine', 'CrtnScore', 'CrtnYes', 'D-Dimer > 3',\n",
              "       'DDimerYes', 'DEMENT', 'DM Complicated', 'DM Simple', 'Ddimer', 'Death',\n",
              "       'Derivation cohort', 'Ferritin', 'Ferritin > 300', 'FerritinYes',\n",
              "       'Glucose', 'Glucose <60 or > 500', 'GlucoseYese', 'IL6', 'IL6 > 150',\n",
              "       'IL6Yes', 'INR', 'INR > 1.2', 'INRYes', 'LOS', 'LOS_Y', 'Lympho',\n",
              "       'LymphoYes', 'Lymphocytes < 1', 'MAP', 'MAP < 70', 'MI', 'MapYes',\n",
              "       'O2 Sat < 94', 'O2SatsYes', 'OldOtherNeuro', 'OldSyncope', 'OsSats',\n",
              "       'OtherBrnLsn', 'PVD', 'Plts', 'PltsScore', 'PltsYes', 'ProCalCYes',\n",
              "       'Procalciton > 0.1', 'Procalcitonin', 'Pure CNS', 'Renal Disease',\n",
              "       'Seizure', 'Severity', 'SodimuYes', 'Sodium', 'Sodium < 139 or > 154',\n",
              "       'Stroke', 'Temp', 'Temp > 38', 'TempYes', 'TropYes', 'Troponin',\n",
              "       'Troponin > 0.1', 'WBC', 'WBC <1.8 or > 4.8', 'WBCYes'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyse Data - Overview Shape\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PKU6Y7vBtKv",
        "outputId": "abbf3a71-7ef2-4de8-d6f6-88ae4cc7fce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4711, 81)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Afficher le type de chaque colonne et null (si présent)\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVE4SDKxB8zh",
        "outputId": "70d4bde6-d644-4faa-8750-9b5997bed6a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4711 entries, 0 to 4710\n",
            "Data columns (total 81 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   Derivation cohort      4711 non-null   int64  \n",
            " 1   LOS_Y                  4711 non-null   int64  \n",
            " 2   LOS                    4711 non-null   int64  \n",
            " 3   Death                  4711 non-null   int64  \n",
            " 4   Age                    4711 non-null   object \n",
            " 5   Severity               4711 non-null   int64  \n",
            " 6   MI                     4711 non-null   int64  \n",
            " 7   PVD                    4711 non-null   int64  \n",
            " 8   CHF                    4711 non-null   int64  \n",
            " 9   CVD                    4711 non-null   int64  \n",
            " 10  DEMENT                 4711 non-null   int64  \n",
            " 11  COPD                   4711 non-null   int64  \n",
            " 12  DM Complicated         4711 non-null   int64  \n",
            " 13  DM Simple              4711 non-null   int64  \n",
            " 14  Renal Disease          4711 non-null   int64  \n",
            " 15  All CNS                4711 non-null   int64  \n",
            " 16  Pure CNS               4711 non-null   int64  \n",
            " 17  Stroke                 4711 non-null   int64  \n",
            " 18  Seizure                4711 non-null   int64  \n",
            " 19  OldSyncope             4711 non-null   int64  \n",
            " 20  OldOtherNeuro          4711 non-null   int64  \n",
            " 21  OtherBrnLsn            4711 non-null   int64  \n",
            " 22  Age.1                  4711 non-null   int64  \n",
            " 23  AgeScore               4711 non-null   int64  \n",
            " 24  O2SatsYes              4711 non-null   int64  \n",
            " 25  OsSats                 4711 non-null   int64  \n",
            " 26  O2 Sat < 94            4711 non-null   int64  \n",
            " 27  TempYes                4711 non-null   int64  \n",
            " 28  Temp                   4711 non-null   float64\n",
            " 29  Temp > 38              4711 non-null   int64  \n",
            " 30  MapYes                 4711 non-null   int64  \n",
            " 31  MAP                    4711 non-null   float64\n",
            " 32  MAP < 70               4711 non-null   int64  \n",
            " 33  DDimerYes              4711 non-null   int64  \n",
            " 34  Ddimer                 4711 non-null   float64\n",
            " 35  D-Dimer > 3            4711 non-null   int64  \n",
            " 36  PltsYes                4711 non-null   int64  \n",
            " 37  Plts                   4711 non-null   int64  \n",
            " 38  PltsScore              4711 non-null   int64  \n",
            " 39  INRYes                 4711 non-null   int64  \n",
            " 40  INR                    4711 non-null   float64\n",
            " 41  INR > 1.2              4711 non-null   int64  \n",
            " 42  BUNYes                 4711 non-null   int64  \n",
            " 43  BUN                    4711 non-null   float64\n",
            " 44  BUN > 30               4711 non-null   int64  \n",
            " 45  CrtnYes                4711 non-null   int64  \n",
            " 46  Creatinine             4711 non-null   float64\n",
            " 47  CrtnScore              4711 non-null   int64  \n",
            " 48  SodimuYes              4711 non-null   int64  \n",
            " 49  Sodium                 4711 non-null   float64\n",
            " 50  Sodium < 139 or > 154  4711 non-null   int64  \n",
            " 51  GlucoseYese            4711 non-null   int64  \n",
            " 52  Glucose                4711 non-null   float64\n",
            " 53  Glucose <60 or > 500   4711 non-null   int64  \n",
            " 54  ASTYes                 4711 non-null   int64  \n",
            " 55  AST                    4711 non-null   float64\n",
            " 56  AST > 40               4711 non-null   int64  \n",
            " 57  ALTYes                 4711 non-null   int64  \n",
            " 58  ALT                    4711 non-null   float64\n",
            " 59  ALT > 40               4711 non-null   int64  \n",
            " 60  WBCYes                 4711 non-null   int64  \n",
            " 61  WBC                    4711 non-null   float64\n",
            " 62  WBC <1.8 or > 4.8      4711 non-null   int64  \n",
            " 63  LymphoYes              4711 non-null   int64  \n",
            " 64  Lympho                 4711 non-null   float64\n",
            " 65  Lymphocytes < 1        4711 non-null   int64  \n",
            " 66  IL6Yes                 4711 non-null   int64  \n",
            " 67  IL6                    4711 non-null   float64\n",
            " 68  IL6 > 150              4711 non-null   int64  \n",
            " 69  FerritinYes            4711 non-null   int64  \n",
            " 70  Ferritin               4711 non-null   float64\n",
            " 71  Ferritin > 300         4711 non-null   int64  \n",
            " 72  CrctProtYes            4711 non-null   int64  \n",
            " 73  CrctProtein            4711 non-null   float64\n",
            " 74  C-Reactive Prot > 10   4711 non-null   int64  \n",
            " 75  ProCalCYes             4711 non-null   int64  \n",
            " 76  Procalcitonin          4711 non-null   float64\n",
            " 77  Procalciton > 0.1      4711 non-null   int64  \n",
            " 78  TropYes                4711 non-null   int64  \n",
            " 79  Troponin               4711 non-null   float64\n",
            " 80  Troponin > 0.1         4711 non-null   int64  \n",
            "dtypes: float64(17), int64(63), object(1)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().any()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_7G6hkHJUGz",
        "outputId": "fa522b74-8ab2-443c-a530-f87a83b885d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Derivation cohort    False\n",
              "LOS_Y                False\n",
              "LOS                  False\n",
              "Death                False\n",
              "Age                  False\n",
              "                     ...  \n",
              "Procalcitonin        False\n",
              "Procalciton > 0.1    False\n",
              "TropYes              False\n",
              "Troponin             False\n",
              "Troponin > 0.1       False\n",
              "Length: 81, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "erH8v0b9KjoU",
        "outputId": "3c9b1ce2-1a8c-4c08-c8b2-080c5c7a2c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Derivation cohort        LOS_Y          LOS        Death     Severity  \\\n",
              "count        4711.000000  4711.000000  4711.000000  4711.000000  4711.000000   \n",
              "mean            0.499682     0.927616     7.160263     0.243685     3.586287   \n",
              "std             0.500053     0.259150     7.029782     0.429350     2.289303   \n",
              "min             0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%             0.000000     1.000000     3.000000     0.000000     2.000000   \n",
              "50%             0.000000     1.000000     5.000000     0.000000     3.000000   \n",
              "75%             1.000000     1.000000     9.000000     0.000000     5.000000   \n",
              "max             1.000000     1.000000    56.000000     1.000000    11.000000   \n",
              "\n",
              "                MI          PVD          CHF          CVD       DEMENT  ...  \\\n",
              "count  4711.000000  4711.000000  4711.000000  4711.000000  4711.000000  ...   \n",
              "mean      0.042666     0.187434     0.114838     0.107408     0.078964  ...   \n",
              "std       0.202125     0.408897     0.318860     0.309664     0.269711  ...   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
              "max       1.000000     2.000000     1.000000     1.000000     1.000000  ...   \n",
              "\n",
              "       Ferritin > 300  CrctProtYes  CrctProtein  C-Reactive Prot > 10  \\\n",
              "count     4711.000000  4711.000000  4711.000000           4711.000000   \n",
              "mean         0.543621     0.836128    10.314919              0.393335   \n",
              "std          0.498146     0.370198    11.223356              0.488542   \n",
              "min          0.000000     0.000000     0.000000              0.000000   \n",
              "25%          0.000000     1.000000     0.900000              0.000000   \n",
              "50%          1.000000     1.000000     6.500000              0.000000   \n",
              "75%          1.000000     1.000000    16.000000              1.000000   \n",
              "max          1.000000     1.000000   100.000100              1.000000   \n",
              "\n",
              "        ProCalCYes  Procalcitonin  Procalciton > 0.1      TropYes  \\\n",
              "count  4711.000000    4711.000000        4711.000000  4711.000000   \n",
              "mean      0.655487       1.585601           0.365952     0.863935   \n",
              "std       0.475260       6.262625           0.481747     0.342893   \n",
              "min       0.000000       0.000000           0.000000     0.000000   \n",
              "25%       0.000000       0.000000           0.000000     1.000000   \n",
              "50%       1.000000       0.100000           0.000000     1.000000   \n",
              "75%       1.000000       0.400000           1.000000     1.000000   \n",
              "max       1.000000      50.000100           1.000000     1.000000   \n",
              "\n",
              "          Troponin  Troponin > 0.1  \n",
              "count  4711.000000     4711.000000  \n",
              "mean      0.051558        0.095521  \n",
              "std       0.268160        0.293965  \n",
              "min       0.000000        0.000000  \n",
              "25%       0.010000        0.000000  \n",
              "50%       0.010000        0.000000  \n",
              "75%       0.020000        0.000000  \n",
              "max       9.560000        1.000000  \n",
              "\n",
              "[8 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4826f689-0bad-478a-ac52-89998d73acc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Derivation cohort</th>\n",
              "      <th>LOS_Y</th>\n",
              "      <th>LOS</th>\n",
              "      <th>Death</th>\n",
              "      <th>Severity</th>\n",
              "      <th>MI</th>\n",
              "      <th>PVD</th>\n",
              "      <th>CHF</th>\n",
              "      <th>CVD</th>\n",
              "      <th>DEMENT</th>\n",
              "      <th>...</th>\n",
              "      <th>Ferritin &gt; 300</th>\n",
              "      <th>CrctProtYes</th>\n",
              "      <th>CrctProtein</th>\n",
              "      <th>C-Reactive Prot &gt; 10</th>\n",
              "      <th>ProCalCYes</th>\n",
              "      <th>Procalcitonin</th>\n",
              "      <th>Procalciton &gt; 0.1</th>\n",
              "      <th>TropYes</th>\n",
              "      <th>Troponin</th>\n",
              "      <th>Troponin &gt; 0.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "      <td>4711.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.499682</td>\n",
              "      <td>0.927616</td>\n",
              "      <td>7.160263</td>\n",
              "      <td>0.243685</td>\n",
              "      <td>3.586287</td>\n",
              "      <td>0.042666</td>\n",
              "      <td>0.187434</td>\n",
              "      <td>0.114838</td>\n",
              "      <td>0.107408</td>\n",
              "      <td>0.078964</td>\n",
              "      <td>...</td>\n",
              "      <td>0.543621</td>\n",
              "      <td>0.836128</td>\n",
              "      <td>10.314919</td>\n",
              "      <td>0.393335</td>\n",
              "      <td>0.655487</td>\n",
              "      <td>1.585601</td>\n",
              "      <td>0.365952</td>\n",
              "      <td>0.863935</td>\n",
              "      <td>0.051558</td>\n",
              "      <td>0.095521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.500053</td>\n",
              "      <td>0.259150</td>\n",
              "      <td>7.029782</td>\n",
              "      <td>0.429350</td>\n",
              "      <td>2.289303</td>\n",
              "      <td>0.202125</td>\n",
              "      <td>0.408897</td>\n",
              "      <td>0.318860</td>\n",
              "      <td>0.309664</td>\n",
              "      <td>0.269711</td>\n",
              "      <td>...</td>\n",
              "      <td>0.498146</td>\n",
              "      <td>0.370198</td>\n",
              "      <td>11.223356</td>\n",
              "      <td>0.488542</td>\n",
              "      <td>0.475260</td>\n",
              "      <td>6.262625</td>\n",
              "      <td>0.481747</td>\n",
              "      <td>0.342893</td>\n",
              "      <td>0.268160</td>\n",
              "      <td>0.293965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>100.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>50.000100</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>9.560000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 80 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4826f689-0bad-478a-ac52-89998d73acc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4826f689-0bad-478a-ac52-89998d73acc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4826f689-0bad-478a-ac52-89998d73acc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data) \n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joBp58WUJH7G",
        "outputId": "e0c05c6e-0163-4ffb-d13f-d3f91f3614fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Derivation cohort  LOS_Y  LOS  Death   Age  Severity  MI  PVD  CHF  CVD  \\\n",
            "0                     1      1    1      0   >80         3   0    0    0    0   \n",
            "1                     1      1    2      1   >60         7   0    1    0    0   \n",
            "2                     1      1    2      1   >80         7   0    1    1    1   \n",
            "3                     1      1   15      0   >70         9   1    0    0    0   \n",
            "4                     1      1    9      0   >70         7   0    0    0    0   \n",
            "...                 ...    ...  ...    ...   ...       ...  ..  ...  ...  ...   \n",
            "4706                  0      1    4      0   >70         4   0    0    0    0   \n",
            "4707                  0      1    2      0   >60         2   0    1    0    0   \n",
            "4708                  0      0    0      0   >60         1   0    1    0    0   \n",
            "4709                  0      0    0      0   >80         3   0    1    0    0   \n",
            "4710                  0      0    0      0  0-60         2   0    1    0    0   \n",
            "\n",
            "      ...  Ferritin > 300  CrctProtYes  CrctProtein  C-Reactive Prot > 10  \\\n",
            "0     ...               0            1       0.4999                     0   \n",
            "1     ...               1            1      14.9000                     1   \n",
            "2     ...               1            1      33.9000                     1   \n",
            "3     ...               1            1      18.4000                     1   \n",
            "4     ...               1            1      11.6000                     1   \n",
            "...   ...             ...          ...          ...                   ...   \n",
            "4706  ...               0            1       1.8000                     0   \n",
            "4707  ...               1            1       3.1000                     0   \n",
            "4708  ...               0            1       0.4999                     0   \n",
            "4709  ...               1            1       8.6000                     0   \n",
            "4710  ...               0            1       0.0000                     0   \n",
            "\n",
            "      ProCalCYes  Procalcitonin  Procalciton > 0.1  TropYes  Troponin  \\\n",
            "0              0         0.0000                  0        1      0.01   \n",
            "1              1         0.6000                  1        1      1.20   \n",
            "2              1         1.2000                  1        0      0.00   \n",
            "3              1         7.3000                  1        1      0.05   \n",
            "4              0         0.0000                  0        1      0.01   \n",
            "...          ...            ...                ...      ...       ...   \n",
            "4706           1         0.0999                  0        1      0.01   \n",
            "4707           1         0.0999                  0        1      0.01   \n",
            "4708           1         0.0000                  0        0      0.00   \n",
            "4709           1         0.1000                  0        1      0.01   \n",
            "4710           1         0.0000                  0        0      0.00   \n",
            "\n",
            "      Troponin > 0.1  \n",
            "0                  0  \n",
            "1                  1  \n",
            "2                  0  \n",
            "3                  0  \n",
            "4                  0  \n",
            "...              ...  \n",
            "4706               0  \n",
            "4707               0  \n",
            "4708               0  \n",
            "4709               0  \n",
            "4710               0  \n",
            "\n",
            "[4711 rows x 81 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#y = data['Death']#Devison de données dépondantes et indépondantes\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "x = data.drop(['Death', 'Severity','Age'], axis=1)\n",
        "y = data['Death']\n",
        "\n",
        "print('x', x.shape)\n",
        "\n",
        "print('y', y)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ65DvN2UuGX",
        "outputId": "ee96c9f0-5267-4bb8-d818-f7d899bc1d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x (4711, 78)\n",
            "y 0       0\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "4706    0\n",
            "4707    0\n",
            "4708    0\n",
            "4709    0\n",
            "4710    0\n",
            "Name: Death, Length: 4711, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#standarisation des données\n",
        "scaler = StandardScaler();\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "print(x_scaled)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFb0G2wzXNTk",
        "outputId": "c8cb770b-00f6-4722-df8b-8f94fa2e3221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.00063701  0.27934215 -0.87640231 ...  0.39685496 -0.15499055\n",
            "  -0.3249754 ]\n",
            " [ 1.00063701  0.27934215 -0.73413528 ...  0.39685496  4.28313254\n",
            "   3.07715597]\n",
            " [ 1.00063701  0.27934215 -0.73413528 ... -2.51981229 -0.1922857\n",
            "  -0.3249754 ]\n",
            " ...\n",
            " [-0.9993634  -3.57983928 -1.01866933 ... -2.51981229 -0.1922857\n",
            "  -0.3249754 ]\n",
            " [-0.9993634  -3.57983928 -1.01866933 ...  0.39685496 -0.15499055\n",
            "  -0.3249754 ]\n",
            " [-0.9993634  -3.57983928 -1.01866933 ... -2.51981229 -0.1922857\n",
            "  -0.3249754 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kZ70bCASU10",
        "outputId": "aaf8f521-c1e8-4338-e149-c6737146f617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x (4711, 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('y', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfBlXuF_Seoi",
        "outputId": "0995b2a2-2c1f-44d7-9bc9-38ae1c57f654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y (4711,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Définir les données de test et d'entrainement , test pour verifier la presision de notre reseau /entraiement : nos data d'entrées\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state= 42)"
      ],
      "metadata": {
        "id": "9FFuI8oqqw-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # initialiser le modele \n",
        "\n",
        "    modele = tf.keras.models.Sequential()\n",
        "    # ajouter la premiere couche \n",
        "    modele.add(tf.keras.layers.Dense(100, activation = 'relu',input_shape = [x_train.shape[1]]))\n",
        "    # couches chachées,\n",
        "    modele.add(tf.keras.layers.Dense(100, activation = 'relu'))\n",
        "    modele.add(tf.keras.layers.Dense(100, activation = 'relu'))\n",
        "    # la fonction de sortie\n",
        "    modele.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "    # Compiler le reseau\n",
        "    modele.compile(loss='binary_crossentropy', optimizer='adam', metrics=['binary_accuracy']) # Accuracy performance metrice\n",
        "    #appliquer le modele sur nos données\n",
        "    training = modele.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=80)\n",
        "    #evaluer le model\n",
        "    score= modele.evaluate(x_train,y_train) \n",
        "    #evaluer la précision\n",
        "    print(\"Précision de l'entraînement : %.2f%%\\n \" % (score[1]*100)) \n",
        "    scoreT= modele.evaluate(x_test,y_test) \n",
        "    print (\"Précision des tests : %.2f%%\\n \" % (scoreT[1]*100))\n",
        "\n",
        "    #2 couche  : 1 RELU et 1 sigmoid\n",
        "    #nombre de noeuds des chouche caché et entrée :50  et  1  pendant 50 epoque =>  Précision de l'entraînement: 97.08% ,Précision des tests :82.61%\n",
        "    #nombre de noeuds des chouche caché et entrée :100 et  1  pendant 50 epoque =>  Précision de l'entraînement : 99.34%   ,Précision des tests : 81.65%\n",
        "\n",
        "    #nombre de noeuds des chouche caché et entrée :50  et  1  pendant 80 epoque =>  Précision de l'entraînement 99.12%   ,Précision des tests : 81.23%\n",
        "    #nombre de noeuds des chouche caché et entrée :100 et  1  pendant 80 epoque =>  Précision de l'entraînement 99.87%  : ,Précision des tests : 81.34%\n",
        "\n",
        "   #nombre de noeuds des chouche caché et entrée :50 et  1  pendant 120 epoque =>  Précision de l'entraînement 99.95%  ,Précision des tests :80.70%\n",
        "   #nombre de noeuds des chouche caché et entrée :100 et  1  pendant 120 epoque =>  Précision de l'entraînement 99.95   ,Précision des tests : 81.55%\n",
        "\n",
        "    #3 couche  : 2 RELU et 1 sigmoid\n",
        "    #nombre de noeuds des chouche caché et entrée :50/50  et  1  pendant 50 epoque =>  Précision de l'entraînement 99.68%: ,Précision des tests :79.22%\n",
        "    #nombre de noeuds des chouche caché et entrée :100/100 et  1  pendant 50 epoque =>  Précision de l'entraînement : 99.97%  ,Précision des tests : 81.97%\n",
        "\n",
        "    #nombre de noeuds des chouche caché et entrée :50/50  et  1  pendant 80 epoque =>  Précision de l'entraînement  99.97%   ,Précision des tests : 80.06\n",
        "    #nombre de noeuds des chouche caché et entrée :100/100  et  1  pendant 80 epoque =>  Précision de l'entraînement 99.97%  : ,Précision des tests : 80.81%\n",
        "\n",
        "   #nombre de noeuds des chouche caché et entrée :50/50 et  1  pendant 120 epoque =>  Précision de l'entraînement 99.97%   ,Précision des tests : 80.59%\n",
        "   #nombre de noeuds des chouche caché et entrée :100/100  et  1  pendant 120 epoque =>  Précision de l'entraînement 99.97%   ,Précision des tests : 81.97%\n",
        "\n",
        "    #4 couche  : 3 RELU et 1 sigmoid \n",
        "    #nombre de noeuds des chouche caché et entrée :50/50/50  et  1  pendant 50 epoque =>  Précision de l'entraînement 99.95%: ,Précision des tests : 78.47%\n",
        "    #nombre de noeuds des chouche caché et entrée :100/100/100  et  1  pendant 50 epoque =>  Précision de l'entraînement 99.95%: ,Précision des tests : 80.91%\n",
        "\n",
        "    #nombre de noeuds des chouche caché et entrée :50/50/50  et  1  pendant 80 epoque =>  Précision de l'entraînement  99.97% ,Précision des tests : 79.96%\n",
        "    #####nombre de noeuds des chouche caché et entrée :100/100/100  et  1  pendant 80 epoque =>  Précision de l'entraînement  99.97% : ,Précision des tests :  82.50%\n",
        "  \n",
        "    #nombre de noeuds des chouche caché et entrée :100/200/100  et  1  pendant 80 epoque =>  Précision de l'entraînement  99.97% : ,Précision des tests :  82.50%\n",
        "     #nombre de noeuds des chouche caché et entrée :100/100/100/100 (softmax)et   pendant 80 epoque =>  Précision de l'entraînement 23.99%  : ,Précision des tests :  \n",
        "\n",
        "   #nombre de noeuds des chouche caché et entrée :50/50/50  et  1  pendant 120 epoque =>  Précision de l'entraînement 99.97%   ,Précision des tests : 81.02% \n",
        "   #nombre de noeuds des chouche caché et entrée :100/100/100  et  1  pendant 120 epoque =>  Précision de l'entraînement  99.87%  : ,Précision des tests : 80.38%\n",
        "\n",
        "   #5 couche  : 4 RELU et 1 sigmoid \n",
        "   #nombre de noeuds des chouche caché et entrée :50/50/50/50  et  1  pendant 50 epoque =>  Précision de l'entraînement 99.92%  ,Précision des tests : 79.53%\n",
        "   #nombre de noeuds des chouche caché et entrée :100/100/100/100 et  1  pendant 50 epoque =>  Précision de l'entraînement 99.68% ,Précision des tests : 78.37%\n",
        "\n",
        "   #nombre de noeuds des chouche caché et entrée :50/50/50/50 et  1  pendant 80 epoque =>  Précision de l'entraînement 99.97% ,Précision des tests : 80.38%\n",
        "   #nombre de noeuds des chouche caché et entrée :100/100/100/100 et  1  pendant 80 epoque =>  Précision de l'entraînement  99.58%  : ,Précision des tests :  80.17%\n",
        "\n",
        "   #nombre de noeuds des chouche caché et entrée :50/50/50/50  et  1  pendant 120 epoque =>  Précision de l'entraînement 99.89%  ,Précision des tests : 80.91%\n",
        "   #nombre de noeuds des chouche caché et entrée :100/100/100/100 et  1  pendant 120 epoque =>  Précision de l'entraînement  98.67%  : ,Précision des tests : 80.49%\n",
        "   \n",
        "   #Couche terminale Softmax précision trés faible \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfCsQzgUErdX",
        "outputId": "fb67aadb-8611-4b2f-d683-e4ca8c257241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.4453 - binary_accuracy: 0.7983 - val_loss: 0.3935 - val_binary_accuracy: 0.8240\n",
            "Epoch 2/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3524 - binary_accuracy: 0.8498 - val_loss: 0.3873 - val_binary_accuracy: 0.8229\n",
            "Epoch 3/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.3168 - binary_accuracy: 0.8652 - val_loss: 0.4101 - val_binary_accuracy: 0.8229\n",
            "Epoch 4/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2890 - binary_accuracy: 0.8715 - val_loss: 0.4023 - val_binary_accuracy: 0.8208\n",
            "Epoch 5/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2574 - binary_accuracy: 0.8891 - val_loss: 0.4091 - val_binary_accuracy: 0.8356\n",
            "Epoch 6/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2298 - binary_accuracy: 0.9026 - val_loss: 0.4292 - val_binary_accuracy: 0.8155\n",
            "Epoch 7/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.2013 - binary_accuracy: 0.9206 - val_loss: 0.4764 - val_binary_accuracy: 0.8059\n",
            "Epoch 8/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1748 - binary_accuracy: 0.9315 - val_loss: 0.5282 - val_binary_accuracy: 0.8208\n",
            "Epoch 9/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1315 - binary_accuracy: 0.9509 - val_loss: 0.5740 - val_binary_accuracy: 0.8208\n",
            "Epoch 10/80\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.1080 - binary_accuracy: 0.9631 - val_loss: 0.6295 - val_binary_accuracy: 0.8165\n",
            "Epoch 11/80\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.0849 - binary_accuracy: 0.9713 - val_loss: 0.7602 - val_binary_accuracy: 0.8208\n",
            "Epoch 12/80\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.0806 - binary_accuracy: 0.9788 - val_loss: 0.7213 - val_binary_accuracy: 0.8165\n",
            "Epoch 13/80\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.0514 - binary_accuracy: 0.9857 - val_loss: 0.8081 - val_binary_accuracy: 0.8144\n",
            "Epoch 14/80\n",
            "118/118 [==============================] - 1s 8ms/step - loss: 0.0586 - binary_accuracy: 0.9849 - val_loss: 0.9177 - val_binary_accuracy: 0.8134\n",
            "Epoch 15/80\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.0535 - binary_accuracy: 0.9833 - val_loss: 0.9094 - val_binary_accuracy: 0.8197\n",
            "Epoch 16/80\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.0301 - binary_accuracy: 0.9934 - val_loss: 1.0237 - val_binary_accuracy: 0.8091\n",
            "Epoch 17/80\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.0237 - binary_accuracy: 0.9958 - val_loss: 1.0629 - val_binary_accuracy: 0.8165\n",
            "Epoch 18/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0232 - binary_accuracy: 0.9960 - val_loss: 1.0856 - val_binary_accuracy: 0.8134\n",
            "Epoch 19/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0146 - binary_accuracy: 0.9973 - val_loss: 1.1414 - val_binary_accuracy: 0.8165\n",
            "Epoch 20/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0168 - binary_accuracy: 0.9965 - val_loss: 1.1028 - val_binary_accuracy: 0.8112\n",
            "Epoch 21/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0690 - binary_accuracy: 0.9743 - val_loss: 1.0515 - val_binary_accuracy: 0.8144\n",
            "Epoch 22/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0602 - binary_accuracy: 0.9812 - val_loss: 0.9181 - val_binary_accuracy: 0.7996\n",
            "Epoch 23/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0351 - binary_accuracy: 0.9894 - val_loss: 1.1189 - val_binary_accuracy: 0.8229\n",
            "Epoch 24/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0192 - binary_accuracy: 0.9968 - val_loss: 1.0707 - val_binary_accuracy: 0.8218\n",
            "Epoch 25/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0047 - binary_accuracy: 0.9995 - val_loss: 1.1483 - val_binary_accuracy: 0.8250\n",
            "Epoch 26/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0055 - binary_accuracy: 0.9992 - val_loss: 1.2323 - val_binary_accuracy: 0.8261\n",
            "Epoch 27/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0053 - binary_accuracy: 0.9989 - val_loss: 1.2266 - val_binary_accuracy: 0.8155\n",
            "Epoch 28/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0062 - binary_accuracy: 0.9981 - val_loss: 1.2504 - val_binary_accuracy: 0.8134\n",
            "Epoch 29/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0033 - binary_accuracy: 0.9989 - val_loss: 1.3322 - val_binary_accuracy: 0.8250\n",
            "Epoch 30/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0036 - binary_accuracy: 0.9992 - val_loss: 1.3100 - val_binary_accuracy: 0.8208\n",
            "Epoch 31/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0055 - binary_accuracy: 0.9987 - val_loss: 1.3796 - val_binary_accuracy: 0.8218\n",
            "Epoch 32/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0445 - binary_accuracy: 0.9833 - val_loss: 1.2272 - val_binary_accuracy: 0.8176\n",
            "Epoch 33/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0670 - binary_accuracy: 0.9774 - val_loss: 1.0623 - val_binary_accuracy: 0.8070\n",
            "Epoch 34/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0543 - binary_accuracy: 0.9841 - val_loss: 1.0429 - val_binary_accuracy: 0.8123\n",
            "Epoch 35/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0254 - binary_accuracy: 0.9915 - val_loss: 1.1457 - val_binary_accuracy: 0.8091\n",
            "Epoch 36/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0081 - binary_accuracy: 0.9984 - val_loss: 1.2187 - val_binary_accuracy: 0.8208\n",
            "Epoch 37/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0031 - binary_accuracy: 0.9995 - val_loss: 1.2639 - val_binary_accuracy: 0.8123\n",
            "Epoch 38/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0023 - binary_accuracy: 0.9995 - val_loss: 1.3336 - val_binary_accuracy: 0.8208\n",
            "Epoch 39/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0032 - binary_accuracy: 0.9992 - val_loss: 1.3351 - val_binary_accuracy: 0.8144\n",
            "Epoch 40/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0060 - binary_accuracy: 0.9987 - val_loss: 1.3398 - val_binary_accuracy: 0.8208\n",
            "Epoch 41/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0135 - binary_accuracy: 0.9958 - val_loss: 1.4107 - val_binary_accuracy: 0.8155\n",
            "Epoch 42/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0065 - binary_accuracy: 0.9981 - val_loss: 1.4317 - val_binary_accuracy: 0.8017\n",
            "Epoch 43/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0101 - binary_accuracy: 0.9968 - val_loss: 1.4498 - val_binary_accuracy: 0.8208\n",
            "Epoch 44/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0132 - binary_accuracy: 0.9955 - val_loss: 1.5991 - val_binary_accuracy: 0.8038\n",
            "Epoch 45/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0479 - binary_accuracy: 0.9835 - val_loss: 1.3707 - val_binary_accuracy: 0.8081\n",
            "Epoch 46/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0426 - binary_accuracy: 0.9867 - val_loss: 1.1269 - val_binary_accuracy: 0.8134\n",
            "Epoch 47/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0099 - binary_accuracy: 0.9965 - val_loss: 1.3483 - val_binary_accuracy: 0.8144\n",
            "Epoch 48/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0081 - binary_accuracy: 0.9979 - val_loss: 1.3457 - val_binary_accuracy: 0.8187\n",
            "Epoch 49/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0045 - binary_accuracy: 0.9987 - val_loss: 1.4007 - val_binary_accuracy: 0.8134\n",
            "Epoch 50/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0097 - binary_accuracy: 0.9963 - val_loss: 1.3385 - val_binary_accuracy: 0.8091\n",
            "Epoch 51/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0071 - binary_accuracy: 0.9979 - val_loss: 1.3471 - val_binary_accuracy: 0.8176\n",
            "Epoch 52/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0020 - binary_accuracy: 0.9997 - val_loss: 1.4053 - val_binary_accuracy: 0.8155\n",
            "Epoch 53/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0019 - binary_accuracy: 0.9995 - val_loss: 1.4640 - val_binary_accuracy: 0.8134\n",
            "Epoch 54/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0012 - binary_accuracy: 0.9997 - val_loss: 1.4748 - val_binary_accuracy: 0.8176\n",
            "Epoch 55/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 1.5187 - val_binary_accuracy: 0.8197\n",
            "Epoch 56/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0010 - binary_accuracy: 0.9995 - val_loss: 1.5573 - val_binary_accuracy: 0.8176\n",
            "Epoch 57/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0017 - binary_accuracy: 0.9997 - val_loss: 1.5400 - val_binary_accuracy: 0.8197\n",
            "Epoch 58/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0012 - binary_accuracy: 0.9995 - val_loss: 1.5912 - val_binary_accuracy: 0.8155\n",
            "Epoch 59/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0034 - binary_accuracy: 0.9989 - val_loss: 1.5540 - val_binary_accuracy: 0.8165\n",
            "Epoch 60/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0015 - binary_accuracy: 0.9997 - val_loss: 1.6079 - val_binary_accuracy: 0.8187\n",
            "Epoch 61/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0049 - binary_accuracy: 0.9984 - val_loss: 1.5102 - val_binary_accuracy: 0.8165\n",
            "Epoch 62/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0024 - binary_accuracy: 0.9992 - val_loss: 1.5344 - val_binary_accuracy: 0.8155\n",
            "Epoch 63/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 1.6035 - val_binary_accuracy: 0.8187\n",
            "Epoch 64/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0011 - binary_accuracy: 0.9995 - val_loss: 1.6257 - val_binary_accuracy: 0.8155\n",
            "Epoch 65/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 7.7940e-04 - binary_accuracy: 0.9995 - val_loss: 1.6691 - val_binary_accuracy: 0.8187\n",
            "Epoch 66/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0010 - binary_accuracy: 0.9997 - val_loss: 1.6782 - val_binary_accuracy: 0.8176\n",
            "Epoch 67/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0011 - binary_accuracy: 0.9997 - val_loss: 1.7064 - val_binary_accuracy: 0.8187\n",
            "Epoch 68/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0027 - binary_accuracy: 0.9995 - val_loss: 1.6650 - val_binary_accuracy: 0.8144\n",
            "Epoch 69/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0033 - binary_accuracy: 0.9989 - val_loss: 1.6566 - val_binary_accuracy: 0.8049\n",
            "Epoch 70/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0559 - binary_accuracy: 0.9814 - val_loss: 1.0046 - val_binary_accuracy: 0.8070\n",
            "Epoch 71/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.1064 - binary_accuracy: 0.9554 - val_loss: 0.9782 - val_binary_accuracy: 0.7943\n",
            "Epoch 72/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0373 - binary_accuracy: 0.9878 - val_loss: 1.2972 - val_binary_accuracy: 0.8017\n",
            "Epoch 73/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0309 - binary_accuracy: 0.9910 - val_loss: 1.2380 - val_binary_accuracy: 0.8155\n",
            "Epoch 74/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0067 - binary_accuracy: 0.9976 - val_loss: 1.3703 - val_binary_accuracy: 0.8102\n",
            "Epoch 75/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0036 - binary_accuracy: 0.9992 - val_loss: 1.5206 - val_binary_accuracy: 0.8144\n",
            "Epoch 76/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0061 - binary_accuracy: 0.9984 - val_loss: 1.5307 - val_binary_accuracy: 0.8081\n",
            "Epoch 77/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0034 - binary_accuracy: 0.9992 - val_loss: 1.5621 - val_binary_accuracy: 0.8165\n",
            "Epoch 78/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0057 - binary_accuracy: 0.9981 - val_loss: 1.7384 - val_binary_accuracy: 0.8091\n",
            "Epoch 79/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0037 - binary_accuracy: 0.9992 - val_loss: 1.7223 - val_binary_accuracy: 0.8081\n",
            "Epoch 80/80\n",
            "118/118 [==============================] - 0s 3ms/step - loss: 0.0014 - binary_accuracy: 0.9997 - val_loss: 1.7832 - val_binary_accuracy: 0.8102\n",
            "118/118 [==============================] - 0s 2ms/step - loss: 8.5061e-04 - binary_accuracy: 0.9995\n",
            "Précision de l'entraînement : 99.95%\n",
            " \n",
            "30/30 [==============================] - 0s 1ms/step - loss: 1.7832 - binary_accuracy: 0.8102\n",
            "Précision des tests : 81.02%\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = modele.predict(x_test) \n",
        "y_pred = (y_pred > 0.1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = ['Survivre', 'Décéder']\n",
        " \n",
        "sns.heatmap(cm, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        " \n",
        "plt.xlabel('Données prédites ')\n",
        "plt.ylabel('Données actuelles')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "iaVM2mWOgWUY",
        "outputId": "ffbcc8a6-a1fa-4cb6-d4ec-667e185026e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(91.68, 0.5, 'Données actuelles')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    #visualisation\n",
        "    import matplotlib.pyplot as plt\n",
        "    %matplotlib inline\n",
        "    import seaborn as sns\n",
        "    sns.set()\n",
        "    acc =training.history['binary_accuracy']\n",
        "    loss = training.history['loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    plt.plot(epochs, acc, '-', label='Training accuracy')\n",
        "    plt.plot(epochs, loss, ':', label='Validation accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "3655t_b0zSHd",
        "outputId": "dca57179-4bd1-42cb-f98c-626436a85cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev \n",
        "from sklearn import preprocessing \n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn import linear_model \n",
        "from sklearn import datasets \n",
        "  \n",
        "# Scaled data\n",
        "X_train_scaled = scaler.fit_transform(x_train)\n",
        "X_test_scaled = scaler.transform(x_test) # transform only!\n",
        "lr = linear_model.LogisticRegression() \n",
        "\n",
        "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=1) \n",
        "\n",
        "lst_accu_stratified = [] \n",
        "   \n",
        "for train_index, test_index in skf.split(x, y): \n",
        "    x_train_fold, x_test_fold = x_scaled[train_index], x_scaled[test_index] \n",
        "    y_train_fold, y_test_fold = y[train_index], y[test_index] \n",
        "    lr.fit(x_train_fold, y_train_fold) \n",
        "    lst_accu_stratified.append(lr.score(x_test_fold, y_test_fold)) \n",
        "   \n",
        "print('List of possible accuracy:', lst_accu_stratified) \n",
        "print('\\nMaximum Accuracy That can be obtained from this model is:', \n",
        "      max(lst_accu_stratified)*100, '%') \n",
        "print('\\nMinimum Accuracy:', \n",
        "      min(lst_accu_stratified)*100, '%') \n",
        "print('\\nOverall Accuracy:', \n",
        "      mean(lst_accu_stratified)*100, '%') \n",
        "print('\\nStandard Deviation is:', stdev(lst_accu_stratified)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OqFR4ijY1sL",
        "outputId": "400223fe-b4f5-4f68-a654-40013e544a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of possible accuracy: [0.7754237288135594, 0.8771186440677966, 0.8516949152542372, 0.8686440677966102, 0.8389830508474576, 0.8516949152542372, 0.8347457627118644, 0.826271186440678, 0.8177966101694916, 0.826271186440678, 0.8347457627118644, 0.8808510638297873, 0.8340425531914893, 0.8127659574468085, 0.8382978723404255, 0.8340425531914893, 0.8340425531914893, 0.8127659574468085, 0.8553191489361702, 0.8382978723404255]\n",
            "\n",
            "Maximum Accuracy That can be obtained from this model is: 88.08510638297872 %\n",
            "\n",
            "Minimum Accuracy: 77.54237288135593 %\n",
            "\n",
            "Overall Accuracy: 83.71907681211684 %\n",
            "\n",
            "Standard Deviation is: 0.023962049840526224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "from numpy import absolute\n",
        "from statistics import mean, stdev \n",
        "\n",
        "#define cross-validation \n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "#build multiple linear regression model\n",
        "model = LinearRegression()\n",
        "#use k-fold CV to evaluate model\n",
        "scores = cross_val_score(model, x, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "#view mean absolute error\n",
        "mean(absolute(scores))\n",
        "#D'après la sortie, nous pouvons voir que l'erreur absolue moyenne (MAE) était  de 0.26609024532166065 . \n",
        "#Autrement dit, l'erreur absolue moyenne entre la prédiction du modèle et les données réelles observées est de 0.26609024532166065.\n",
        "#on constate qu'elle est trés faible donc nous pouvons conclure que le modèle des donnés est capable de prédire les observations réelles.\n",
        "\n",
        " #L'exécution de l'exemple utilise l'ensemble de données, \n",
        " #puis évalue un modèle de régression logistique sur celui-ci à l'aide d'une validation croisée 10 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRY2x1aKWP_x",
        "outputId": "98fad7c3-bfa4-4c04-be45-1f6cd9a7d903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26609024532166065"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modele.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi331yVmgV51",
        "outputId": "8dea6130-0e17-4b9f-a1ce-ed385466bf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 100)               7900      \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,201\n",
            "Trainable params: 28,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}